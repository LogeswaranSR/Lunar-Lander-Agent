{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c0af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Loges\\anaconda3\\envs\\rl-env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.losses import MSE\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bab0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b634a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = env.observation_space.shape\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bba42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5003f9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Loges\\anaconda3\\envs\\rl-env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_network = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=state_size),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_actions, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ceb35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_q_network = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=state_size),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_actions, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd2a350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = pd.DataFrame(columns=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(experience, gamma, q_network, target_q_network):\n",
    "    states, action, rewards, next_states, done_vals = experiences[:]\n",
    "    max_qsa = tf.reduce_max(target_q_network(next_states), axis=1)\n",
    "    y_targets = rewards + (gamma * max_qsa * (i-done_vals))\n",
    "    q_values = q_network(states)\n",
    "    q_values = tf.gather_nd(q_values, tf.stack([tf.range(q_values.shape[0]),\n",
    "                                               tf.cast(actions, tf.int32)], axis=1))\n",
    "    loss = MSE(y_targets, q_values)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def agent_learn(experiences, gamma):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(experience, gamma, q_network, target_q_network)\n",
    "    \n",
    "    gradients = tape.gradient(loss, q_network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, q_network.trainable_variables))\n",
    "    update_target_network(q_network, target_q_network)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f06cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c35db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e49561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7f986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b6643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec3f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6f707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2823d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
